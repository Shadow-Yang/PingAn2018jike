# PingAn2018jike
'''
在这个比赛中，有一些收获。
1.在基本的数据分析之后，在基本的数据填充之后，可以对数据的主要特征进行随机森林（RF）或者Xgboost方法提取重要特征。
2.在进行极度数据正负样本不均衡的二分类时，在计算机硬件允许的前提下，可以进行SMOTE方法对多数样本进行下采样，对少数样本进行上采样。
3.不能一味地相信单模型的可靠性，在单模型参数调整好之后，还是需要对其他次优的模型，进行融合，从而得到更优的效果。（improve.py的分数就是比27test的结果好，也可能是个人原因。）
4.还是要多挑战自己，要尝试进行grid search方法调参，这样自己的模型参数才更具说服力。
5.加油少年！
'''
